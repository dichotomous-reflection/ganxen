{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODuURT1ZPVnU"
      },
      "source": [
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision import models\r\n",
        "import torch.optim as optim\r\n",
        "from time import time\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcdYnCYzLaIf",
        "outputId": "e9f13948-185d-495b-8850-b5e10e934d85"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/') "
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47N9RF_ZI7UO"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision import models\r\n",
        "import torch.optim as optim\r\n",
        "from time import time\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxnCsjubJdxf"
      },
      "source": [
        "import argparse\r\n",
        "import itertools\r\n",
        "import os\r\n",
        "import random\r\n",
        "\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torch.utils.data\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.utils as vutils\r\n",
        "from PIL import Image\r\n",
        "from tqdm import tqdm\r\n"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbJ84ASFJBYx"
      },
      "source": [
        "from os import listdir\r\n",
        "from numpy import asarray\r\n",
        "from numpy import vstack\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from numpy import savez_compressed\r\n",
        "import torch\r\n",
        "from torchvision import transforms\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "from PIL import Image\r\n",
        "transform=transforms.Compose([\r\n",
        "    #transforms.Resize(256,256),\r\n",
        "    #transforms.RandomCrop(args.image_size),\r\n",
        "    transforms.RandomHorizontalFlip(),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "transform2=transforms.Compose([\r\n",
        "    transforms.Resize(256),\r\n",
        "    transforms.CenterCrop(256),\r\n",
        "    transforms.RandomHorizontalFlip(),\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "# load all images in a directory into memory\r\n",
        "def load_image(path, size=(256,256)):\r\n",
        "#def load_image(path, size=(512,512)):\r\n",
        "    #data_list = list()\r\n",
        "    # enumerate filenames in directory, assume all are images\r\n",
        "    \r\n",
        "    # load and resize the image\r\n",
        "    pixels = load_img(path, target_size=size)\r\n",
        "    # convert to numpy array\r\n",
        "    \r\n",
        "    pixels = transform(pixels)\r\n",
        "    pixels = img_to_array(pixels)\r\n",
        "    # store\r\n",
        "    return pixels\r\n",
        "\r\n",
        "def load_image2(img, size=(256,256)):\r\n",
        "#def load_image(path, size=(512,512)):\r\n",
        "    #data_list = list()\r\n",
        "    # enumerate filenames in directory, assume all are images\r\n",
        "    \r\n",
        "    # load and resize the image\r\n",
        "    #pixels = load_img(img, target_size=size)\r\n",
        "    # convert to numpy array\r\n",
        "    \r\n",
        "    pixels = transform2(img)\r\n",
        "    pixels = img_to_array(pixels)\r\n",
        "    # store\r\n",
        "    return pixels"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBFb3_6WMOBc"
      },
      "source": [
        "image=load_image(\"/content/gdrive/MyDrive/Herdentorswallmühle,_Windmühle,_Bremen.jpg\")"
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EubHUHWmJmI_"
      },
      "source": [
        "image=torch.from_numpy(image)"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jzy9M2rI2u6",
        "outputId": "0be3094e-ae83-45fa-ebfb-4200705e7c1a"
      },
      "source": [
        "image=torch.unsqueeze(image,0)\r\n",
        "image.size()"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 256, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hROALCDqJ3f6"
      },
      "source": [
        "from torchvision.utils import save_image\r\n",
        "from IPython.display import clear_output\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np"
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4VK9nb3Hkqs"
      },
      "source": [
        ""
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SziMJcRdH0GN"
      },
      "source": [
        ""
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "QDsSrmbeTbp9",
        "outputId": "5f00d06f-34c5-436c-ad4c-d329001fddbf"
      },
      "source": [
        "#segnet for generator\n",
        "\"\"\"class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder (downsampling)\n",
        "        self.enc_conv0 =nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size= 3, padding=1),nn.BatchNorm2d(64), \n",
        "                                      nn.ReLU(),nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3, padding=1),nn.BatchNorm2d(64), nn.ReLU())\n",
        "        \n",
        "        self.pool0 = nn.Sequential(nn.MaxPool2d(2,2, return_indices=True))\n",
        "        \n",
        "        self.enc_conv1 = nn.Sequential(nn.Conv2d(in_channels=64,out_channels=128, kernel_size=3, padding=1),nn.BatchNorm2d(128), nn.ReLU(),\n",
        "                                       nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3, padding=1),nn.BatchNorm2d(128), nn.ReLU())\n",
        "        \n",
        "        self.pool1  = nn.MaxPool2d(kernel_size=2, stride= 2, return_indices=True)# 128 -> 64\n",
        "\n",
        "        self.enc_conv2 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),nn.BatchNorm2d(256), nn.ReLU(),\n",
        "                                       nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3, padding=1),nn.BatchNorm2d(256), nn.ReLU(),\n",
        "                                       nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,padding=1),nn.BatchNorm2d(256), nn.ReLU())\n",
        "\n",
        "        self.pool2 =  nn.MaxPool2d(kernel_size=2, stride= 2, return_indices=True) # 64 -> 32\n",
        "\n",
        "        self.enc_conv3 = nn.Sequential(nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3, padding=1),nn.BatchNorm2d(512), nn.ReLU(), \n",
        "                                       nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3, padding=1),nn.BatchNorm2d(512), nn.ReLU(),\n",
        "                                       nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3, padding=1),nn.BatchNorm2d(512), nn.ReLU())\n",
        "        \n",
        "        self.pool3  = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)# 32 -> 16\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottleneck_conv = nn.Sequential(nn.Conv2d(in_channels=512,out_channels=512,kernel_size=1), nn.BatchNorm2d(512),\n",
        "                                             nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3, padding=1), nn.BatchNorm2d(512),\n",
        "                                             nn.Conv2d(in_channels=512,out_channels=512,kernel_size=1), nn.BatchNorm2d(512))\n",
        "\n",
        "        # decoder (upsampling)\n",
        "        self.upsample0 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 16 -> 32\n",
        "        \n",
        "        self.dec_conv0 =nn.Sequential(nn.Conv2d(in_channels=512,out_channels=256,kernel_size=3, padding=1),nn.BatchNorm2d(256),nn.ReLU(),\n",
        "                                      nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3, padding=1), nn.BatchNorm2d(256),nn.ReLU(),\n",
        "                                      nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3, padding=1), nn.BatchNorm2d(256),nn.ReLU())\n",
        "        \n",
        "        self.upsample1 = nn.MaxUnpool2d(kernel_size=2, stride=2)# 32 -> 64\n",
        "        \n",
        "        self.dec_conv1 = nn.Sequential(nn.Conv2d(in_channels=256,out_channels=128,kernel_size=1), nn.BatchNorm2d(128), nn.ReLU(), \n",
        "                                       nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1), nn.BatchNorm2d(128),nn.ReLU(),\n",
        "                                       nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1), nn.BatchNorm2d(128),nn.ReLU())\n",
        "        \n",
        "        self.upsample2 =nn.MaxUnpool2d(kernel_size=2, stride=2)   # 64 -> 128\n",
        "        \n",
        "        self.dec_conv2 = nn.Sequential(nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3, padding=1), nn.BatchNorm2d(64),nn.ReLU(), \n",
        "                                       nn.Conv2d(in_channels=64,out_channels=64, kernel_size=3, padding=1), nn.BatchNorm2d(64),nn.ReLU())\n",
        "        \n",
        "        self.upsample3 =  nn.MaxUnpool2d(kernel_size=2, stride=2) # 128 -> 256\n",
        "        \n",
        "        self.dec_conv3 =nn.Sequential(nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), \n",
        "                                      nn.Conv2d(in_channels=64,out_channels=3,kernel_size=3, padding=1)\n",
        "                                      )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        x=x.to(device)\n",
        "        e0, indx0 =self.pool0(self.enc_conv0(x))\n",
        "        \n",
        "        #print(e0.shape, indx0.shape)\n",
        "        e1, indx1= self.pool1(self.enc_conv1(e0))\n",
        "        \n",
        "        #print(\"e11\",e1.shape, indx1.shape)\n",
        "        e2, indx2= self.pool2(self.enc_conv2(e1))\n",
        "        \n",
        "        #print(\"e21\",e2.shape, indx2.shape)\n",
        "        e3, indx3= self.pool3(self.enc_conv3(e2))\n",
        "        \n",
        "        #print(\"31\",e3.shape, indx3.shape)\n",
        "\n",
        "        # bottleneck\n",
        "        b = self.bottleneck_conv(e3)\n",
        "        #print(\"b\",b.shape, indx3.shape)\n",
        "        # decoder\n",
        "        d0 =self.upsample0(b, indx3) \n",
        "        #print(d0.shape, indx3.shape)\n",
        "        d01=self.dec_conv0(d0)\n",
        "        #print(d01.shape)\n",
        "        d1 = self.upsample1(d01, indx2) \n",
        "        d11=self.dec_conv1(d1)\n",
        "        #print(d11.shape)\n",
        "        d2 = self.upsample2(d11, indx1) \n",
        "        d21=self.dec_conv2(d2)\n",
        "        #print(d21.shape)\n",
        "        d3 = self.upsample3(d21, indx0) \n",
        "        d31= self.dec_conv3(d3) # no activation\n",
        "        return d31.cuda()\"\"\"\n",
        "        "
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'class SegNet(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n\\n        # encoder (downsampling)\\n        self.enc_conv0 =nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size= 3, padding=1),nn.BatchNorm2d(64), \\n                                      nn.ReLU(),nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3, padding=1),nn.BatchNorm2d(64), nn.ReLU())\\n        \\n        self.pool0 = nn.Sequential(nn.MaxPool2d(2,2, return_indices=True))\\n        \\n        self.enc_conv1 = nn.Sequential(nn.Conv2d(in_channels=64,out_channels=128, kernel_size=3, padding=1),nn.BatchNorm2d(128), nn.ReLU(),\\n                                       nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3, padding=1),nn.BatchNorm2d(128), nn.ReLU())\\n        \\n        self.pool1  = nn.MaxPool2d(kernel_size=2, stride= 2, return_indices=True)# 128 -> 64\\n\\n        self.enc_conv2 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),nn.BatchNorm2d(256), nn.ReLU(),\\n                                       nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3, padding=1),nn.BatchNorm2d(256), nn.ReLU(),\\n                                       nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,padding=1),nn.BatchNorm2d(256), nn.ReLU())\\n\\n        self.pool2 =  nn.MaxPool2d(kernel_size=2, stride= 2, return_indices=True) # 64 -> 32\\n\\n        self.enc_conv3 = nn.Sequential(nn.Conv2d(in_channels=256,out_channels=512,kernel_size=3, padding=1),nn.BatchNorm2d(512), nn.ReLU(), \\n                                       nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3, padding=1),nn.BatchNorm2d(512), nn.ReLU(),\\n                                       nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3, padding=1),nn.BatchNorm2d(512), nn.ReLU())\\n        \\n        self.pool3  = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)# 32 -> 16\\n\\n        # bottleneck\\n        self.bottleneck_conv = nn.Sequential(nn.Conv2d(in_channels=512,out_channels=512,kernel_size=1), nn.BatchNorm2d(512),\\n                                             nn.Conv2d(in_channels=512,out_channels=512,kernel_size=3, padding=1), nn.BatchNorm2d(512),\\n                                             nn.Conv2d(in_channels=512,out_channels=512,kernel_size=1), nn.BatchNorm2d(512))\\n\\n        # decoder (upsampling)\\n        self.upsample0 = nn.MaxUnpool2d(kernel_size=2, stride=2) # 16 -> 32\\n        \\n        self.dec_conv0 =nn.Sequential(nn.Conv2d(in_channels=512,out_channels=256,kernel_size=3, padding=1),nn.BatchNorm2d(256),nn.ReLU(),\\n                                      nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3, padding=1), nn.BatchNorm2d(256),nn.ReLU(),\\n                                      nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3, padding=1), nn.BatchNorm2d(256),nn.ReLU())\\n        \\n        self.upsample1 = nn.MaxUnpool2d(kernel_size=2, stride=2)# 32 -> 64\\n        \\n        self.dec_conv1 = nn.Sequential(nn.Conv2d(in_channels=256,out_channels=128,kernel_size=1), nn.BatchNorm2d(128), nn.ReLU(), \\n                                       nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1), nn.BatchNorm2d(128),nn.ReLU(),\\n                                       nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,padding=1), nn.BatchNorm2d(128),nn.ReLU())\\n        \\n        self.upsample2 =nn.MaxUnpool2d(kernel_size=2, stride=2)   # 64 -> 128\\n        \\n        self.dec_conv2 = nn.Sequential(nn.Conv2d(in_channels=128,out_channels=64,kernel_size=3, padding=1), nn.BatchNorm2d(64),nn.ReLU(), \\n                                       nn.Conv2d(in_channels=64,out_channels=64, kernel_size=3, padding=1), nn.BatchNorm2d(64),nn.ReLU())\\n        \\n        self.upsample3 =  nn.MaxUnpool2d(kernel_size=2, stride=2) # 128 -> 256\\n        \\n        self.dec_conv3 =nn.Sequential(nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), \\n                                      nn.Conv2d(in_channels=64,out_channels=3,kernel_size=3, padding=1)\\n                                      )\\n\\n    def forward(self, x):\\n        # encoder\\n        x=x.to(device)\\n        e0, indx0 =self.pool0(self.enc_conv0(x))\\n        \\n        #print(e0.shape, indx0.shape)\\n        e1, indx1= self.pool1(self.enc_conv1(e0))\\n        \\n        #print(\"e11\",e1.shape, indx1.shape)\\n        e2, indx2= self.pool2(self.enc_conv2(e1))\\n        \\n        #print(\"e21\",e2.shape, indx2.shape)\\n        e3, indx3= self.pool3(self.enc_conv3(e2))\\n        \\n        #print(\"31\",e3.shape, indx3.shape)\\n\\n        # bottleneck\\n        b = self.bottleneck_conv(e3)\\n        #print(\"b\",b.shape, indx3.shape)\\n        # decoder\\n        d0 =self.upsample0(b, indx3) \\n        #print(d0.shape, indx3.shape)\\n        d01=self.dec_conv0(d0)\\n        #print(d01.shape)\\n        d1 = self.upsample1(d01, indx2) \\n        d11=self.dec_conv1(d1)\\n        #print(d11.shape)\\n        d2 = self.upsample2(d11, indx1) \\n        d21=self.dec_conv2(d2)\\n        #print(d21.shape)\\n        d3 = self.upsample3(d21, indx0) \\n        d31= self.dec_conv3(d3) # no activation\\n        return d31.cuda()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQpv6ABwxTP"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "class ConvolNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ConvolNet, self).__init__()\r\n",
        "\r\n",
        "        self.main = nn.Sequential(\r\n",
        "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "\r\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\r\n",
        "            nn.InstanceNorm2d(128),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "\r\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\r\n",
        "            nn.InstanceNorm2d(256),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "\r\n",
        "            nn.Conv2d(256, 512, 4, padding=1),\r\n",
        "            nn.InstanceNorm2d(512),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "\r\n",
        "            nn.Conv2d(512, 1, 4, padding=1),\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.main(x)\r\n",
        "        x = F.avg_pool2d(x, x.size()[2:])\r\n",
        "        x = torch.flatten(x, 1)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "class SegNet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(SegNet, self).__init__()\r\n",
        "        self.main = nn.Sequential(\r\n",
        "            # Initial convolution block\r\n",
        "            nn.ReflectionPad2d(3),\r\n",
        "            nn.Conv2d(3, 64, 7),\r\n",
        "            nn.InstanceNorm2d(64),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "\r\n",
        "            # Downsampling\r\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\r\n",
        "            nn.InstanceNorm2d(128),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\r\n",
        "            nn.InstanceNorm2d(256),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "\r\n",
        "            # Residual blocks\r\n",
        "            ResidualBlock(256),\r\n",
        "            ResidualBlock(256),\r\n",
        "            ResidualBlock(256),\r\n",
        "            ResidualBlock(256),\r\n",
        "            ResidualBlock(256),\r\n",
        "            ResidualBlock(256),\r\n",
        "            ResidualBlock(256),\r\n",
        "            ResidualBlock(256),\r\n",
        "            ResidualBlock(256),\r\n",
        "\r\n",
        "            # Upsampling\r\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\r\n",
        "            nn.InstanceNorm2d(128),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\r\n",
        "            nn.InstanceNorm2d(64),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "\r\n",
        "            # Output layer\r\n",
        "            nn.ReflectionPad2d(3),\r\n",
        "            nn.Conv2d(64, 3, 7),\r\n",
        "            #nn.Tanh()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self.main(x)\r\n",
        "\r\n",
        "\r\n",
        "class ResidualBlock(nn.Module):\r\n",
        "    def __init__(self, in_channels):\r\n",
        "        super(ResidualBlock, self).__init__()\r\n",
        "\r\n",
        "        self.res = nn.Sequential(nn.ReflectionPad2d(1),\r\n",
        "                                 nn.Conv2d(in_channels, in_channels, 3),\r\n",
        "                                 nn.InstanceNorm2d(in_channels),\r\n",
        "                                 nn.ReLU(inplace=True),\r\n",
        "                                 nn.ReflectionPad2d(1),\r\n",
        "                                 nn.Conv2d(in_channels, in_channels, 3),\r\n",
        "                                 nn.InstanceNorm2d(in_channels))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return x + self.res(x)"
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDiIRqmPPEeP"
      },
      "source": [
        "model1=torch.load(\"/content/gdrive/MyDrive/g_model_BtoA_000088.h5\")"
      ],
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXaPe7K_FCHu"
      },
      "source": [
        "model=torch.load(\"/content/gdrive/MyDrive/g_model_AtoB_000191.h5\")"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weIDmDCyNLZ8"
      },
      "source": [
        "DEVICE = torch.device(\"cuda\")\r\n",
        "device=torch.device(\"cuda\")"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTedSY1m6Wsq"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RksqbHePKAFW"
      },
      "source": [
        "def show(pic):\r\n",
        "    \r\n",
        "    pyplot.subplot(2, 1 , 2)\r\n",
        "    pyplot.axis('off')\r\n",
        "    pic=torch.squeeze(pic)\r\n",
        "    ch, h, w= pic.size()\r\n",
        "    #fake1=fake[i].reshape(h, w, ch)\r\n",
        "    fake1=pic.permute(1, 2, 0)\r\n",
        "    fake1=fake1.cpu()\r\n",
        "    fake1=fake1.detach().numpy()\r\n",
        "    mean = np.array([0.5, 0.5, 0.5])\r\n",
        "    std = np.array([0.5, 0.5, 0.5])\r\n",
        "    #mean = np.array([0.4914, 0.4822, 0.4465])\r\n",
        "    #std = np.array([0.2023, 0.1994, 0.2010])\r\n",
        "    fake1 = std * fake1 + mean\r\n",
        "    fake1 = np.clip(fake1, 0, 1)\r\n",
        "    #fake1=Image.fromarray(fake1)\r\n",
        "    #resized_image = t(fake1)\r\n",
        "    #fake1=img_to_array(fake1)\r\n",
        "    fake1 = cv2.resize(fake1, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\r\n",
        "    plt.imshow(fake1)\r\n",
        "    #pyplot.show()\r\n",
        "    filename1 = '/content/gdrive/MyDrive/Outputs/pic.jpg'\r\n",
        "    pyplot.savefig(filename1)\r\n",
        "    pyplot.close()\r\n",
        "    return fake1"
      ],
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXIqdinEJ_3C"
      },
      "source": [
        "def predict_one_sample(model, inputs, device=DEVICE):\r\n",
        "    \"\"\"Предсказание, для одной картинки\"\"\"\r\n",
        "    with torch.no_grad():\r\n",
        "        inputs = inputs.to(device)\r\n",
        "        model.eval()\r\n",
        "        res = model(inputs).cpu()\r\n",
        "        #probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\r\n",
        "        res= show(res)\r\n",
        "    return res\r\n"
      ],
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhCHF2KfK7p9"
      },
      "source": [
        "from matplotlib import pyplot\r\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "IxHecisnNRv2",
        "outputId": "94d4f859-34b0-44c7-de7a-25675f520891"
      },
      "source": [
        "k=predict_one_sample(model,image)"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-398-71bfaf73fb83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_one_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-396-f7a56df96278>\u001b[0m in \u001b[0;36mpredict_one_sample\u001b[0;34m(model, inputs, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-390-45a1dbe1a7ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'SegNet' object has no attribute 'main'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtTzP9Ix8mgK"
      },
      "source": [
        "def workit(model,image):\r\n",
        "    k=predict_one_sample(model,image)\r\n",
        "    plt.imshow(k)\r\n",
        "    plt.axis('off')\r\n",
        "    #pyplot.show()\r\n",
        "    filename1 = '/content/gdrive/MyDrive/Outputs/pic1.jpg'\r\n",
        "    pyplot.savefig(filename1, bbox_inches='tight')\r\n",
        "    pyplot.close()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVQUvon7B56e"
      },
      "source": [
        "workit(model,image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQj-sFMYaIwN"
      },
      "source": [
        "!pip install telegram-send\r\n",
        "import telegram_send\r\n",
        "telegram_token = '1583691133:AAHrob5dmPKtm5LDGibCB5xBAgCzsxeL3eg'\r\n",
        "chat_id = '642852704'\r\n",
        "path_config = telegram_send.get_config_path()\r\n",
        "with open(path_config, 'w') as f:\r\n",
        "    f.write(f'[telegram]\\ntoken = {telegram_token}\\nchat_id = {chat_id}')\r\n",
        "telegram_send.send(messages=[\"Telegram bot synced!\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfRxSLiSfZP-"
      },
      "source": [
        "!pip3 install requests > /dev/null\r\n",
        "!pip3 install pyTelegramBotAPI > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBl7JQwbfPxJ"
      },
      "source": [
        "import logging\r\n",
        "from io import BytesIO\r\n",
        "import numpy as np\r\n",
        "import requests\r\n",
        "from PIL import Image\r\n",
        "from skimage.transform import rescale, resize\r\n",
        "import telebot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kQozx5Yd7BV"
      },
      "source": [
        "MSG_GREETING = \"Hi!\"\r\n",
        "\r\n",
        "bot = telebot.TeleBot(telegram_token)\r\n",
        "telebot.logger.setLevel(logging.DEBUG)\r\n",
        "\r\n",
        "@bot.message_handler(commands=['help', 'start'])\r\n",
        "def send_welcome(message):\r\n",
        "    bot.reply_to(message, MSG_GREETING)\r\n",
        "\r\n",
        "\r\n",
        "@bot.message_handler(func=lambda message: True)\r\n",
        "def echo_message(message):\r\n",
        "    bot.reply_to(message, message.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWGGeDNygEcm"
      },
      "source": [
        "@bot.message_handler(content_types= [\"photo\"])\r\n",
        "def pixelate_photo(message):\r\n",
        "    bot.send_message(message.chat.id, \"Got your photo. Start working..\")\r\n",
        "    # Getting photo\r\n",
        "    file_info = bot.get_file(message.photo[-1].file_id)\r\n",
        "    r = requests.get('https://api.telegram.org/file/bot{0}/{1}'.format(telegram_token, file_info.file_path))\r\n",
        "    #img = np.array(Image.open(BytesIO(r.content)))\r\n",
        "    img = Image.open(BytesIO(r.content))\r\n",
        "    img=load_image2(img)\r\n",
        "    image=torch.from_numpy(img)\r\n",
        "    image=torch.unsqueeze(image,0)\r\n",
        "    # Process\r\n",
        "    #res = pixel_me.pixelate(img)['img_segm_small_w_contour']\r\n",
        "    res=workit(model,image)\r\n",
        "    \"\"\"plt.imshow(res)\r\n",
        "    #pyplot.show()\r\n",
        "    filename1 = '/content/gdrive/MyDrive/Outputs/res.jpg'\r\n",
        "    pyplot.savefig(filename1)\r\n",
        "    pyplot.close()\"\"\"\r\n",
        "\r\n",
        "    # Resizing\r\n",
        "    #res = rescale(res, (int(512 / res.shape[0]), int(512 / res.shape[0]), 1),\r\n",
        "                           #anti_aliasing=False, order=0)\r\n",
        "    # Sending back\r\n",
        "    buf = BytesIO()\r\n",
        "    #res = (1/(2*2.25)) * res + 0.5\r\n",
        "    #plt.imsave(buf, res, format='jpg')\r\n",
        "    #bot.send_photo(message.chat.id, buf.getvalue())\r\n",
        "    res=load_img('/content/gdrive/MyDrive/Outputs/pic1.jpg')\r\n",
        "    bot.send_photo(message.chat.id, res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_6yiSknjI8K"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRJF3Meegzif"
      },
      "source": [
        "bot.polling()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}